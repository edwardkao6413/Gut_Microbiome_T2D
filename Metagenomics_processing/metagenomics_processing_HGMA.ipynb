{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb1027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "import math\n",
    "from scipy.stats import chi2\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import composition_stats as cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b9d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data prep\n",
    "hmp_metadata = pd.read_csv(r\"C:\\Users\\edwar\\Desktop\\Melbourne\\research_project\\curated_metagenomics\\raw_data\\HMP_2019_t2d.relative_abundance_metadata.csv\")\n",
    "hmp_rawdata = pd.read_csv(r\"C:\\Users\\edwar\\Desktop\\Melbourne\\research_project\\curated_metagenomics\\raw_data\\HMP_2019_t2d.relative_abundance_rawdata.csv\")\n",
    "\n",
    "karl_metadata = pd.read_csv(r\"C:\\Users\\edwar\\Desktop\\Melbourne\\research_project\\curated_metagenomics\\raw_data\\KarlssonFH_2013.relative_abundance_metadata.csv\")\n",
    "karl_rawdata = pd.read_csv(r\"C:\\Users\\edwar\\Desktop\\Melbourne\\research_project\\curated_metagenomics\\raw_data\\KarlssonFH_2013.relative_abundance_rawdata.csv\")\n",
    "\n",
    "lij_metadata = pd.read_csv(r\"C:\\Users\\edwar\\Desktop\\Melbourne\\research_project\\curated_metagenomics\\raw_data\\LiJ_2014.relative_abundance_metadata.csv\")\n",
    "lij_rawdata = pd.read_csv(r\"C:\\Users\\edwar\\Desktop\\Melbourne\\research_project\\curated_metagenomics\\raw_data\\LiJ_2014.relative_abundance_rawdata.csv\")\n",
    "\n",
    "yuj_metadata = pd.read_csv(r\"C:\\Users\\edwar\\Desktop\\Melbourne\\research_project\\curated_metagenomics\\raw_data\\YuJ_2015.relative_abundance_metadata.csv\")\n",
    "yuj_rawdata = pd.read_csv(r\"C:\\Users\\edwar\\Desktop\\Melbourne\\research_project\\curated_metagenomics\\raw_data\\YuJ_2015.relative_abundance_rawdata.csv\")\n",
    "\n",
    "feng_metadata = pd.read_csv(r\"C:\\Users\\edwar\\Desktop\\Melbourne\\research_project\\curated_metagenomics\\raw_data\\FengQ_2015.relative_abundance_metadata.csv\")\n",
    "feng_rawdata = pd.read_csv(r\"C:\\Users\\edwar\\Desktop\\Melbourne\\research_project\\curated_metagenomics\\raw_data\\FengQ_2015.relative_abundance_rawdata.csv\")\n",
    "\n",
    "qin_metadata = pd.read_csv(r\"C:\\Users\\edwar\\Desktop\\Melbourne\\research_project\\curated_metagenomics\\raw_data\\QinJ_2012.relative_abundance_metadata.csv\")\n",
    "qin_rawdata = pd.read_csv(r\"C:\\Users\\edwar\\Desktop\\Melbourne\\research_project\\curated_metagenomics\\raw_data\\QinJ_2012.relative_abundance_rawdata.csv\")\n",
    "\n",
    "sank_metadata = pd.read_csv(r\"C:\\Users\\edwar\\Desktop\\Melbourne\\research_project\\curated_metagenomics\\raw_data\\SankaranarayananK_2015.relative_abundance_metadata.csv\")\n",
    "sank_rawdata = pd.read_csv(r\"C:\\Users\\edwar\\Desktop\\Melbourne\\research_project\\curated_metagenomics\\raw_data\\SankaranarayananK_2015.relative_abundance_rawdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894f4ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required basic functions for data cleaning and consistency\n",
    "\n",
    "# Low counts removal\n",
    "def low_counts_rm(data_offset, thres = 0.01):\n",
    "    \"\"\"\n",
    "    data_offset: pandas.dataframe.\n",
    "    thres: float, default value is 0.01\n",
    "    \"\"\"\n",
    "    col_sum = data_offset.sum(axis = 0)\n",
    "    ttl_sum = col_sum.sum()\n",
    "    keep_otu = col_sum[(col_sum * 100 / ttl_sum) > thres].index\n",
    "    data_offset_v2 = data_offset[keep_otu]\n",
    "    data_offset_v2 = data_offset_v2.astype(float)\n",
    "    return data_offset_v2, keep_otu\n",
    "\n",
    "# Combine the samples with their health condition\n",
    "def label_data(rawdata, metadata):\n",
    "    \"\"\"\n",
    "    rawdata: pandas.dataframe, metagenomics counts or abundance matrix.\n",
    "    metadata: pandas.dataframe, metadata with column \"disease\" for health status and index as sample ID.\n",
    "    \"\"\"\n",
    "    taxa_lst = rawdata['FeatureID']\n",
    "    rawdata_v1 = rawdata.T.drop(['FeatureID'])\n",
    "    rawdata_v1.columns = list(taxa_lst)\n",
    "    rawdata_v1 = rawdata_v1.drop(['Unnamed: 0']).reset_index()\n",
    "    return rawdata_v1.merge(metadata[['Unnamed: 0', 'disease']], how = 'right', left_on = ['index'],  right_on = ['Unnamed: 0']).drop(['index', 'Unnamed: 0'], axis = 1)\n",
    "\n",
    "# Derived the samples with targeted disease and control group\n",
    "def take_sample(data):\n",
    "    \"\"\"\n",
    "    data: pandas.dataframe, the output from label data including biological matrix and health status\n",
    "    \"\"\"\n",
    "    data.loc[data['disease'].str.contains('T2D'), 'disease'] = 'T2D'\n",
    "    data.loc[data['disease'].str.contains('healthy'), 'disease'] = 'healthy'\n",
    "    data = data[data['disease'].isin(['T2D', 'healthy'])].reset_index().drop(['index'], axis = 1)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a6acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing the metagenomics data, including offset added and low counts removal\n",
    "\n",
    "def split_processing_single(data, study, thres = 0.01):\n",
    "    \"\"\"\n",
    "    data: pandas.dataframe, the counts matrix with well-cleaned data.\n",
    "    study: str, indicate the different study/batch/platform of data generation.\n",
    "    thres: float, indicate the threshold for low counts removal, mainly for metagenomics seq data.\n",
    "    \"\"\"\n",
    "    data_hea = data[data['disease'] == 'healthy'].reset_index().drop(['index'], axis = 1)\n",
    "    data_t2d = data[data['disease'] == 'T2D'].reset_index().drop(['index'], axis = 1)\n",
    "    data_hea_offset = data_hea.iloc[:, 0:-2] + 1\n",
    "    data_t2d_offset = data_t2d.iloc[:, 0:-2] + 1\n",
    "    data_heainfo = low_counts_rm(data_hea_offset, thres)\n",
    "    data_t2dinfo = low_counts_rm(data_t2d_offset, thres)\n",
    "    Union_taxa = list(set(data_heainfo[1]) | set(data_t2dinfo[1]))\n",
    "    data_v1 = data[Union_taxa]\n",
    "    data_v1 = data_v1.astype('float64')\n",
    "    try:\n",
    "        data_v1['study'] = study\n",
    "    except:\n",
    "        pass\n",
    "    data_v1['disease'] = data['disease']\n",
    "    return data_v1\n",
    "\n",
    "# CLR transformation\n",
    "def clr_trans(data, last_ver_data, study_name):\n",
    "    \"\"\"\n",
    "    data: pandas.dataframe, the output from split_processing_single().\n",
    "    last_ver_data: pandas.dataframe, the output from label_data() followed by take_sample().\n",
    "    study_name: str, same as the study parameter in split_processing_single().\n",
    "    \"\"\"\n",
    "    if 'disease' in list(data.columns):\n",
    "        data = data.drop(['disease'], axis = 1)\n",
    "    if 'study' in list(data.columns):\n",
    "        data = data.drop(['study'], axis = 1)\n",
    "    data_v1 = pd.DataFrame(cs.clr(cs.closure(data + 1)))\n",
    "    data_v1.columns = list(data.columns)\n",
    "    data_v1['disease'] = last_ver_data['disease']\n",
    "    data_v1['study'] = study_name\n",
    "    return data_v1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2476ea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing the data\n",
    "hmp_data_raw1 = take_sample(label_data(hmp_rawdata, hmp_metadata))\n",
    "karl_data_raw1 = take_sample(label_data(karl_rawdata, karl_metadata))\n",
    "lij_data_raw1 = take_sample(label_data(lij_rawdata, lij_metadata))\n",
    "yuj_data_raw1 = take_sample(label_data(yuj_rawdata, yuj_metadata))\n",
    "feng_data_raw1 = take_sample(label_data(feng_rawdata, feng_metadata))\n",
    "sank_data_raw1 = take_sample(label_data(sank_rawdata, sank_metadata))\n",
    "qin_data_raw1 = take_sample(label_data(qin_rawdata, qin_metadata))\n",
    "\n",
    "hmp_data = split_processing_single(data = hmp_data_raw1, study = 'hmp2019', thres = 0.0001)\n",
    "karl_data = split_processing_single(data = karl_data_raw1, study = 'karl2013', thres = 0.0001)\n",
    "lij_data = split_processing_single(data = lij_data_raw1, study = 'lij2014', thres = 0.0001)\n",
    "yuj_data = split_processing_single(data = yuj_data_raw1, study = 'yuj2015', thres = 0.0001)\n",
    "feng_data = split_processing_single(data = feng_data_raw1, study = 'feng2015', thres = 0.0001)\n",
    "sank_data = split_processing_single(data = sank_data_raw1, study = 'sank2015', thres = 0.0001)\n",
    "qin_data = split_processing_single(data = qin_data_raw1, study = 'qin2012', thres = 0.0001)\n",
    "\n",
    "hmp_data_fv = clr_trans(hmp_data, hmp_data_raw1, 'hmp2019')\n",
    "karl_data_fv = clr_trans(karl_data, karl_data_raw1, 'karl2013')\n",
    "lij_data_fv = clr_trans(lij_data, lij_data_raw1, 'lij2014')\n",
    "yuj_data_fv = clr_trans(yuj_data, yuj_data_raw1, 'yuj2015')\n",
    "feng_data_fv = clr_trans(feng_data, feng_data_raw1, 'feng2015')\n",
    "sank_data_fv = clr_trans(sank_data, sank_data_raw1, 'sank2015')\n",
    "qin_data_fv = clr_trans(qin_data, qin_data_raw1, 'qin2012')\n",
    "\n",
    "inte_data = pd.concat([hmp_data_fv, karl_data_fv, lij_data_fv, yuj_data_fv, feng_data_fv], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46229904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove study-specific taxa (Also put in the R scripts)\n",
    "df = pd.DataFrame()\n",
    "\n",
    "studies = inte_data['study'].unique()\n",
    "df['species'] = []\n",
    "for study in studies:\n",
    "    df[study] = []\n",
    "\n",
    "taxa_lst = list(inte_data.drop(['study', 'disease'], axis = 1).columns)\n",
    "studies = list(inte_data['study'].unique())\n",
    "for species in taxa_lst:\n",
    "    df_taxa = pd.DataFrame()\n",
    "    df_taxa['species'] = [species]\n",
    "    for study in studies:\n",
    "        if len(inte_data[inte_data['study'] == study][species].unique()) == 1:\n",
    "            df_taxa[study] = ['x']\n",
    "        else:\n",
    "            df_taxa[study] = ['Exist']\n",
    "    df = pd.concat([df, df_taxa]).reset_index().drop(['index'], axis = 1)\n",
    "\n",
    "df['Exist_count'] = ''\n",
    "df['Exist_count'] = df[list(df.columns)[1:-1]].apply(lambda row:np.sum(row == 'Exist'), axis = 1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
